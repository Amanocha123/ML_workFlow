{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "365c4e8e",
        "outputId": "4ebbcaba-7de7-4655-db05-c9b29427556b"
      },
      "source": [
        "!pip install mlflow"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: mlflow-skinny==3.5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.5.1)\n",
            "Requirement already satisfied: mlflow-tracing==3.5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.5.1)\n",
            "Requirement already satisfied: Flask-CORS<7 in /usr/local/lib/python3.12/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.0)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.12/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.2)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (8.3.0)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (0.70.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (0.120.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (2.11.10)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (1.1.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.5.1->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.5.1->mlflow) (0.48.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.5.1->mlflow) (0.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.5.1->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.5.1->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (2025.10.5)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.5.1->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9PhWvmHkQLTx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jBKuLfejQMRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RerAjC-J7vp",
        "outputId": "e92cd7e4-ec22-409e-f6a2-926599aad6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/10/29 13:55:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Data Creation ---\n",
            "âœ… Created 1000 samples with 4 features and 'salary_target'.\n",
            "\n",
            "--- 2. Exploratory Data Analysis (EDA) ---\n",
            "\n",
            "[Data Head]:\n",
            "   age  experience_years  city_factor  project_score  salary_target\n",
            "0   58          1.042470          1.2      80.656506  146556.140638\n",
            "1   48          8.404396          1.2      74.561058  126611.047815\n",
            "2   34          9.106862          1.2      91.890754  159919.942917\n",
            "3   27          1.228108          1.2      74.229094   90106.349851\n",
            "4   40          2.359060          1.2      48.404513  148725.670776\n",
            "\n",
            "[Descriptive Statistics]:\n",
            "                   count           mean           std           min  \\\n",
            "age               1000.0      39.991000     11.780055     20.000000   \n",
            "experience_years  1000.0       5.031007      2.844953      0.002375   \n",
            "city_factor       1000.0       0.996800      0.164246      0.800000   \n",
            "project_score     1000.0      75.222940     14.670964     29.707318   \n",
            "salary_target     1000.0  142243.932839  23693.181328  68274.851360   \n",
            "\n",
            "                            25%            50%            75%            max  \n",
            "age                   30.000000      41.000000      50.250000      59.000000  \n",
            "experience_years       2.541406       5.145848       7.481941       9.993535  \n",
            "city_factor            0.800000       1.000000       1.200000       1.200000  \n",
            "project_score         65.468831      75.013001      85.002292     133.893566  \n",
            "salary_target     126852.108932  143138.618622  158970.938853  206967.483232  \n",
            "\n",
            "[Feature Correlation with Target]:\n",
            "salary_target       1.000000\n",
            "experience_years    0.577942\n",
            "age                 0.469058\n",
            "city_factor         0.157673\n",
            "project_score       0.118914\n",
            "Name: salary_target, dtype: float64\n",
            "ðŸ’¡ EDA complete. Features show clear correlation with the target.\n",
            "\n",
            "--- 3. Preprocessing and Splitting ---\n",
            "âœ… Data split into Train (800) and Test (200) sets.\n",
            "âœ… Features scaled using StandardScaler.\n",
            "\n",
            "--- 4. Training and MLflow Tracking ---\n",
            "ðŸ”— MLflow Experiment set to: 'Regression_Model_Comparison_Demo'\n",
            "\n",
            "[MLflow Run 1: Linear Regression]\n",
            "   Test MAE: $12201.28, R2: 0.6086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/10/29 13:56:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ… Model and metrics logged to MLflow Run ID: 8ccfc75d41c84c9bbb22a24136eb5cc4\n",
            "\n",
            "[MLflow Run 2: Random Forest Regressor]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# --- Configuration ---\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "EXPERIMENT_NAME = \"Regression_Model_Comparison_Demo\"\n",
        "\n",
        "def create_synthetic_data(n_samples=1000):\n",
        "    \"\"\"\n",
        "    Creates a synthetic dataset for a regression task.\n",
        "    Target (y) is linearly dependent on features with added noise.\n",
        "    \"\"\"\n",
        "    print(\"--- 1. Data Creation ---\")\n",
        "    np.random.seed(RANDOM_STATE)\n",
        "\n",
        "    # Generate features\n",
        "    data = {\n",
        "        'age': np.random.randint(20, 60, n_samples),\n",
        "        'experience_years': np.random.rand(n_samples) * 10,\n",
        "        'city_factor': np.random.choice([0.8, 1.0, 1.2], n_samples),\n",
        "        'project_score': np.random.normal(loc=75, scale=15, size=n_samples)\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Calculate continuous target variable (Salary Prediction)\n",
        "    # y = 50000 + 1000*age + 5000*exp + 20000*city_factor + 100*score + noise\n",
        "    df['salary_target'] = (\n",
        "        50000 +\n",
        "        df['age'] * 1000 +\n",
        "        df['experience_years'] * 5000 +\n",
        "        df['city_factor'] * 20000 +\n",
        "        df['project_score'] * 100 +\n",
        "        np.random.normal(0, 15000, n_samples) # Add significant noise\n",
        "    )\n",
        "\n",
        "    # Ensure target is positive\n",
        "    df['salary_target'] = df['salary_target'].apply(lambda x: max(10000, x))\n",
        "\n",
        "    print(f\"âœ… Created {n_samples} samples with 4 features and 'salary_target'.\")\n",
        "    return df\n",
        "\n",
        "def perform_eda(df):\n",
        "    \"\"\"Prints basic EDA information.\"\"\"\n",
        "    print(\"\\n--- 2. Exploratory Data Analysis (EDA) ---\")\n",
        "\n",
        "    # Print the first few rows\n",
        "    print(\"\\n[Data Head]:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Print descriptive statistics\n",
        "    print(\"\\n[Descriptive Statistics]:\")\n",
        "    print(df.describe().T)\n",
        "\n",
        "    # Print correlation with the target\n",
        "    print(\"\\n[Feature Correlation with Target]:\")\n",
        "    print(df.corr()['salary_target'].sort_values(ascending=False))\n",
        "\n",
        "    # Note: In a real project, you would also create visualizations (histograms, scatter plots)\n",
        "    print(\"ðŸ’¡ EDA complete. Features show clear correlation with the target.\")\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Splits the data and performs standard scaling on features.\n",
        "    Standard Scaling is essential for Linear Regression performance.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- 3. Preprocessing and Splitting ---\")\n",
        "\n",
        "    # Define features and target\n",
        "    X = df.drop('salary_target', axis=1)\n",
        "    y = df['salary_target']\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    # Initialize and fit scaler on training features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"âœ… Data split into Train ({len(X_train)}) and Test ({len(X_test)}) sets.\")\n",
        "    print(f\"âœ… Features scaled using StandardScaler.\")\n",
        "\n",
        "    # Return features as DataFrames (for MLflow readability) and scaled numpy arrays (for model training)\n",
        "    X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "    X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "    return X_train_df, X_test_df, y_train, y_test, scaler\n",
        "\n",
        "def evaluate_metrics(y_true, y_pred, prefix):\n",
        "    \"\"\"Calculates and returns standard regression metrics.\"\"\"\n",
        "    metrics = {\n",
        "        f'{prefix}_mse': mean_squared_error(y_true, y_pred),\n",
        "        f'{prefix}_mae': mean_absolute_error(y_true, y_pred),\n",
        "        f'{prefix}_r2': r2_score(y_true, y_pred),\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def train_and_track_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Trains both models and uses MLflow to track parameters, metrics, and models.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- 4. Training and MLflow Tracking ---\")\n",
        "\n",
        "    # Set up MLflow environment\n",
        "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "    print(f\"ðŸ”— MLflow Experiment set to: '{EXPERIMENT_NAME}'\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4a. Linear Regression Training and Tracking\n",
        "    # ------------------------------------------------------------------\n",
        "    with mlflow.start_run(run_name=\"Linear_Regression_Model\"):\n",
        "        print(\"\\n[MLflow Run 1: Linear Regression]\")\n",
        "\n",
        "        # 1. Define Model and Parameters\n",
        "        model_lr = LinearRegression()\n",
        "\n",
        "        # 2. Log Parameters\n",
        "        mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
        "        mlflow.log_param(\"fit_intercept\", model_lr.get_params()['fit_intercept'])\n",
        "        mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
        "        mlflow.log_param(\"test_size\", TEST_SIZE)\n",
        "\n",
        "        # 3. Train Model (on scaled data)\n",
        "        model_lr.fit(X_train, y_train)\n",
        "\n",
        "        # 4. Predict\n",
        "        y_pred_lr = model_lr.predict(X_test)\n",
        "\n",
        "        # 5. Evaluate and Log Metrics\n",
        "        metrics_lr = evaluate_metrics(y_test, y_pred_lr, \"test\")\n",
        "        mlflow.log_metrics(metrics_lr)\n",
        "\n",
        "        print(f\"   Test MAE: ${metrics_lr['test_mae']:.2f}, R2: {metrics_lr['test_r2']:.4f}\")\n",
        "\n",
        "        # 6. Log Model (Artifact)\n",
        "        mlflow.sklearn.log_model(model_lr, \"Linear_Regression_Artifact\")\n",
        "\n",
        "        print(f\"   âœ… Model and metrics logged to MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4b. Random Forest Regressor Training and Tracking\n",
        "    # ------------------------------------------------------------------\n",
        "    with mlflow.start_run(run_name=\"Random_Forest_Model\"):\n",
        "        print(\"\\n[MLflow Run 2: Random Forest Regressor]\")\n",
        "\n",
        "        # 1. Define Model and Parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        model_rf = RandomForestRegressor(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=-1 # Use all cores\n",
        "        )\n",
        "\n",
        "        # 2. Log Parameters\n",
        "        mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "        mlflow.log_param(\"test_size\", TEST_SIZE)\n",
        "\n",
        "        # 3. Train Model (Random Forest is less sensitive to scaling, but we use scaled data for consistency)\n",
        "        model_rf.fit(X_train, y_train)\n",
        "\n",
        "        # 4. Predict\n",
        "        y_pred_rf = model_rf.predict(X_test)\n",
        "\n",
        "        # 5. Evaluate and Log Metrics\n",
        "        metrics_rf = evaluate_metrics(y_test, y_pred_rf, \"test\")\n",
        "        mlflow.log_metrics(metrics_rf)\n",
        "\n",
        "        print(f\"   Test MAE: ${metrics_rf['test_mae']:.2f}, R2: {metrics_rf['test_r2']:.4f}\")\n",
        "\n",
        "        # 6. Log Model (Artifact)\n",
        "        mlflow.sklearn.log_model(model_rf, \"Random_Forest_Artifact\")\n",
        "\n",
        "        print(f\"   âœ… Model and metrics logged to MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    print(\"\\nðŸ All experiments tracked successfully!\")\n",
        "\n",
        "    # Example prediction for comparison\n",
        "    example_metrics = {\n",
        "        \"Linear Regression R2\": metrics_lr['test_r2'],\n",
        "        \"Random Forest R2\": metrics_rf['test_r2']\n",
        "    }\n",
        "\n",
        "    return model_lr, model_rf, example_metrics\n",
        "\n",
        "def make_example_predictions(model_lr, model_rf, X_test, y_test, scaler):\n",
        "    \"\"\"Demonstrates how to use the models for prediction.\"\"\"\n",
        "    print(\"\\n--- 5. Making Example Predictions ---\")\n",
        "\n",
        "    # Select the first test sample for prediction\n",
        "    example_index = 0\n",
        "    # Original (unscaled) features for display\n",
        "    unscaled_features = X_test.iloc[example_index].to_dict()\n",
        "    # Scaled features used for prediction\n",
        "    scaled_features_array = X_test.iloc[example_index].values.reshape(1, -1)\n",
        "    true_value = y_test.iloc[example_index]\n",
        "\n",
        "    # Predict with Linear Regression\n",
        "    pred_lr = model_lr.predict(scaled_features_array)[0]\n",
        "\n",
        "    # Predict with Random Forest\n",
        "    pred_rf = model_rf.predict(scaled_features_array)[0]\n",
        "\n",
        "    print(\"\\n[Input Data]:\")\n",
        "    print(json.dumps(unscaled_features, indent=4))\n",
        "    print(f\"\\n[True Target Value]: ${true_value:.2f}\")\n",
        "    print(\"\\n[Model Predictions]:\")\n",
        "    print(f\"   Linear Regression: ${pred_lr:.2f}\")\n",
        "    print(f\"   Random Forest Regressor: ${pred_rf:.2f}\")\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Orchestrates the entire MLOps workflow.\"\"\"\n",
        "\n",
        "    # 1. Data Creation\n",
        "    df = create_synthetic_data()\n",
        "\n",
        "    # 2. EDA\n",
        "    perform_eda(df)\n",
        "\n",
        "    # 3. Preprocessing\n",
        "    X_train_df, X_test_df, y_train, y_test, scaler = preprocess_data(df)\n",
        "\n",
        "    # 4. Training and Tracking\n",
        "    model_lr, model_rf, summary_metrics = train_and_track_models(\n",
        "        X_train_df, X_test_df, y_train, y_test\n",
        "    )\n",
        "\n",
        "    # 5. Prediction Demo\n",
        "    make_example_predictions(model_lr, model_rf, X_test_df, y_test, scaler)\n",
        "\n",
        "    print(\"\\n\\n---------------------------------------------------\")\n",
        "    print(\"ðŸ“‹ Pipeline Complete!\")\n",
        "    print(f\"Best Model (based on R2 score): {'Random Forest' if summary_metrics['Random Forest R2'] > summary_metrics['Linear Regression R2'] else 'Linear Regression'}\")\n",
        "    print(\"---------------------------------------------------\")\n",
        "    print(\"\\n**NEXT STEP: View Experiment Tracking**\")\n",
        "    print(\"1. Open a new Command Prompt/Terminal.\")\n",
        "    print(\"2. Run the command: `mlflow ui`\")\n",
        "    print(\"3. Open your browser to http://127.0.0.1:5000 to see the detailed comparison of both models.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aab82eba"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# --- Configuration ---\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "EXPERIMENT_NAME = \"Regression_Model_Comparison_Demo\"\n",
        "\n",
        "def create_synthetic_data(n_samples=1000):\n",
        "    \"\"\"\n",
        "    Creates a synthetic dataset for a regression task.\n",
        "    Target (y) is linearly dependent on features with added noise.\n",
        "    \"\"\"\n",
        "    print(\"--- 1. Data Creation ---\")\n",
        "    np.random.seed(RANDOM_STATE)\n",
        "\n",
        "    # Generate features\n",
        "    data = {\n",
        "        'age': np.random.randint(20, 60, n_samples),\n",
        "        'experience_years': np.random.rand(n_samples) * 10,\n",
        "        'city_factor': np.random.choice([0.8, 1.0, 1.2], n_samples),\n",
        "        'project_score': np.random.normal(loc=75, scale=15, size=n_samples)\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Calculate continuous target variable (Salary Prediction)\n",
        "    # y = 50000 + 1000*age + 5000*exp + 20000*city_factor + 100*score + noise\n",
        "    df['salary_target'] = (\n",
        "        50000 +\n",
        "        df['age'] * 1000 +\n",
        "        df['experience_years'] * 5000 +\n",
        "        df['city_factor'] * 20000 +\n",
        "        df['project_score'] * 100 +\n",
        "        np.random.normal(0, 15000, n_samples) # Add significant noise\n",
        "    )\n",
        "\n",
        "    # Ensure target is positive\n",
        "    df['salary_target'] = df['salary_target'].apply(lambda x: max(10000, x))\n",
        "\n",
        "    print(f\"âœ… Created {n_samples} samples with 4 features and 'salary_target'.\")\n",
        "    return df\n",
        "\n",
        "def perform_eda(df):\n",
        "    \"\"\"Prints basic EDA information.\"\"\"\n",
        "    print(\"\\n--- 2. Exploratory Data Analysis (EDA) ---\")\n",
        "\n",
        "    # Print the first few rows\n",
        "    print(\"\\n[Data Head]:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Print descriptive statistics\n",
        "    print(\"\\n[Descriptive Statistics]:\")\n",
        "    print(df.describe().T)\n",
        "\n",
        "    # Print correlation with the target\n",
        "    print(\"\\n[Feature Correlation with Target]:\")\n",
        "    print(df.corr()['salary_target'].sort_values(ascending=False))\n",
        "\n",
        "    # Note: In a real project, you would also create visualizations (histograms, scatter plots)\n",
        "    print(\"ðŸ’¡ EDA complete. Features show clear correlation with the target.\")\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Splits the data and performs standard scaling on features.\n",
        "    Standard Scaling is essential for Linear Regression performance.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- 3. Preprocessing and Splitting ---\")\n",
        "\n",
        "    # Define features and target\n",
        "    X = df.drop('salary_target', axis=1)\n",
        "    y = df['salary_target']\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    # Initialize and fit scaler on training features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"âœ… Data split into Train ({len(X_train)}) and Test ({len(X_test)}) sets.\")\n",
        "    print(f\"âœ… Features scaled using StandardScaler.\")\n",
        "\n",
        "    # Return features as DataFrames (for MLflow readability) and scaled numpy arrays (for model training)\n",
        "    X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "    X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "    return X_train_df, X_test_df, y_train, y_test, scaler\n",
        "\n",
        "def evaluate_metrics(y_true, y_pred, prefix):\n",
        "    \"\"\"Calculates and returns standard regression metrics.\"\"\"\n",
        "    metrics = {\n",
        "        f'{prefix}_mse': mean_squared_error(y_true, y_pred),\n",
        "        f'{prefix}_mae': mean_absolute_error(y_true, y_pred),\n",
        "        f'{prefix}_r2': r2_score(y_true, y_pred),\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def train_and_track_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Trains both models and uses MLflow to track parameters, metrics, and models.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- 4. Training and MLflow Tracking ---\")\n",
        "\n",
        "    # Set up MLflow environment\n",
        "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "    print(f\"ðŸ”— MLflow Experiment set to: '{EXPERIMENT_NAME}'\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4a. Linear Regression Training and Tracking\n",
        "    # ------------------------------------------------------------------\n",
        "    with mlflow.start_run(run_name=\"Linear_Regression_Model\"):\n",
        "        print(\"\\n[MLflow Run 1: Linear Regression]\")\n",
        "\n",
        "        # 1. Define Model and Parameters\n",
        "        model_lr = LinearRegression()\n",
        "\n",
        "        # 2. Log Parameters\n",
        "        mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
        "        mlflow.log_param(\"fit_intercept\", model_lr.get_params()['fit_intercept'])\n",
        "        mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
        "        mlflow.log_param(\"test_size\", TEST_SIZE)\n",
        "\n",
        "        # 3. Train Model (on scaled data)\n",
        "        model_lr.fit(X_train, y_train)\n",
        "\n",
        "        # 4. Predict\n",
        "        y_pred_lr = model_lr.predict(X_test)\n",
        "\n",
        "        # 5. Evaluate and Log Metrics\n",
        "        metrics_lr = evaluate_metrics(y_test, y_pred_lr, \"test\")\n",
        "        mlflow.log_metrics(metrics_lr)\n",
        "\n",
        "        print(f\"   Test MAE: ${metrics_lr['test_mae']:.2f}, R2: {metrics_lr['test_r2']:.4f}\")\n",
        "\n",
        "        # 6. Log Model (Artifact)\n",
        "        mlflow.sklearn.log_model(model_lr, \"Linear_Regression_Artifact\")\n",
        "\n",
        "        print(f\"   âœ… Model and metrics logged to MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4b. Random Forest Regressor Training and Tracking\n",
        "    # ------------------------------------------------------------------\n",
        "    with mlflow.start_run(run_name=\"Random_Forest_Model\"):\n",
        "        print(\"\\n[MLflow Run 2: Random Forest Regressor]\")\n",
        "\n",
        "        # 1. Define Model and Parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        model_rf = RandomForestRegressor(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=-1 # Use all cores\n",
        "        )\n",
        "\n",
        "        # 2. Log Parameters\n",
        "        mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "        mlflow.log_param(\"test_size\", TEST_SIZE)\n",
        "\n",
        "        # 3. Train Model (Random Forest is less sensitive to scaling, but we use scaled data for consistency)\n",
        "        model_rf.fit(X_train, y_train)\n",
        "\n",
        "        # 4. Predict\n",
        "        y_pred_rf = model_rf.predict(X_test)\n",
        "\n",
        "        # 5. Evaluate and Log Metrics\n",
        "        metrics_rf = evaluate_metrics(y_test, y_pred_rf, \"test\")\n",
        "        mlflow.log_metrics(metrics_rf)\n",
        "\n",
        "        print(f\"   Test MAE: ${metrics_rf['test_mae']:.2f}, R2: {metrics_rf['test_r2']:.4f}\")\n",
        "\n",
        "        # 6. Log Model (Artifact)\n",
        "        mlflow.sklearn.log_model(model_rf, \"Random_Forest_Artifact\")\n",
        "\n",
        "        print(f\"   âœ… Model and metrics logged to MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    print(\"\\nðŸ All experiments tracked successfully!\")\n",
        "\n",
        "    # Example prediction for comparison\n",
        "    example_metrics = {\n",
        "        \"Linear Regression R2\": metrics_lr['test_r2'],\n",
        "        \"Random Forest R2\": metrics_rf['test_r2']\n",
        "    }\n",
        "\n",
        "    return model_lr, model_rf, example_metrics\n",
        "\n",
        "def make_example_predictions(model_lr, model_rf, X_test, y_test, scaler):\n",
        "    \"\"\"Demonstrates how to use the models for prediction.\"\"\"\n",
        "    print(\"\\n--- 5. Making Example Predictions ---\")\n",
        "\n",
        "    # Select the first test sample for prediction\n",
        "    example_index = 0\n",
        "    # Original (unscaled) features for display\n",
        "    unscaled_features = X_test.iloc[example_index].to_dict()\n",
        "    # Scaled features used for prediction\n",
        "    scaled_features_array = X_test.iloc[example_index].values.reshape(1, -1)\n",
        "    true_value = y_test.iloc[example_index]\n",
        "\n",
        "    # Predict with Linear Regression\n",
        "    pred_lr = model_lr.predict(scaled_features_array)[0]\n",
        "\n",
        "    # Predict with Random Forest\n",
        "    pred_rf = model_rf.predict(scaled_features_array)[0]\n",
        "\n",
        "    print(\"\\n[Input Data]:\")\n",
        "    print(json.dumps(unscaled_features, indent=4))\n",
        "    print(f\"\\n[True Target Value]: ${true_value:.2f}\")\n",
        "    print(\"\\n[Model Predictions]:\")\n",
        "    print(f\"   Linear Regression: ${pred_lr:.2f}\")\n",
        "    print(f\"   Random Forest Regressor: ${pred_rf:.2f}\")\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Orchestrates the entire MLOps workflow.\"\"\"\n",
        "\n",
        "    # 1. Data Creation\n",
        "    df = create_synthetic_data()\n",
        "\n",
        "    # 2. EDA\n",
        "    perform_eda(df)\n",
        "\n",
        "    # 3. Preprocessing\n",
        "    X_train_df, X_test_df, y_train, y_test, scaler = preprocess_data(df)\n",
        "\n",
        "    # 4. Training and Tracking\n",
        "    model_lr, model_rf, summary_metrics = train_and_track_models(\n",
        "        X_train_df, X_test_df, y_train, y_test\n",
        "    )\n",
        "\n",
        "    # 5. Prediction Demo\n",
        "    make_example_predictions(model_lr, model_rf, X_test_df, y_test, scaler)\n",
        "\n",
        "    print(\"\\n\\n---------------------------------------------------\")\n",
        "    print(\"ðŸ“‹ Pipeline Complete!\")\n",
        "    print(f\"Best Model (based on R2 score): {'Random Forest' if summary_metrics['Random Forest R2'] > summary_metrics['Linear Regression R2'] else 'Linear Regression'}\")\n",
        "    print(\"---------------------------------------------------\")\n",
        "    print(\"\\n**NEXT STEP: View Experiment Tracking**\")\n",
        "    print(\"1. Open a new Command Prompt/Terminal.\")\n",
        "    print(\"2. Run the command: `mlflow ui`\")\n",
        "    print(\"3. Open your browser to http://127.0.0.1:5000 to see the detailed comparison of both models.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6iaXyfIJ-A0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}